{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SsM55uh-6fv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "2p6chuDCStiH",
    "outputId": "aa86a0ee-4b2d-40e3-9f49-30ab3b8d7f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xBNrxPMXTpPE",
    "outputId": "eb7ccdc7-b507-47ec-f073-59814bf4ec6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from keras.utils import to_categorical\n",
    "import random\n",
    "from tensorflow import set_random_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM\n",
    "from keras.layers import Dense, Activation,Flatten\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#set random seed for the session and also for tensorflow that runs in background for keras\n",
    "set_random_seed(123)\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "M_2veojIUMvJ",
    "outputId": "29765925-5324-412a-ccf9-d21967f18bb8"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./drive/My Drive/sentiment review/train.tsv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3c3a88ac51a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./drive/My Drive/sentiment review/train.tsv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./drive/My Drive/sentiment review/test.tsv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'./drive/My Drive/sentiment review/train.tsv' does not exist"
     ]
    }
   ],
   "source": [
    "train= pd.read_csv(\"./drive/My Drive/sentiment review/train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"./drive/My Drive/sentiment review/test.tsv\", sep=\"\\t\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tWAgDxHRUnif",
    "outputId": "8c521775-7067-4a99-e7a5-09e3f04ddf45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'would have a hard time sitting through this one .'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Phrase'][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iq8UE8L9Vid-"
   },
   "outputs": [],
   "source": [
    "def clean_sentences(df):\n",
    "    reviews = []\n",
    "\n",
    "    for sent in tqdm(df['Phrase']):\n",
    "        \n",
    "        #remove html content\n",
    "        review_text = BeautifulSoup(sent).get_text()\n",
    "        \n",
    "        #remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "        #tokenize the sentences\n",
    "        words = word_tokenize(review_text.lower())\n",
    "    \n",
    "        #lemmatize each word to its lemma\n",
    "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "    \n",
    "        reviews.append(lemma_words)\n",
    "\n",
    "    return(reviews)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4437
    },
    "colab_type": "code",
    "id": "olPqLpJRWtPc",
    "outputId": "d03917fb-4afd-45cd-abac-f5ef9c82475b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "aFbY-Ug_WC2N",
    "outputId": "6b25f7e2-7741-4b8e-e13a-e7108a9ed284"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156060/156060 [01:08<00:00, 2281.88it/s]\n",
      "100%|██████████| 66292/66292 [00:28<00:00, 2336.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156060\n",
      "66292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " \n",
    "#cleaned reviews for both train and test set retrieved\n",
    "train_sentences = clean_sentences(train)\n",
    "test_sentences = clean_sentences(test)\n",
    "print(len(train_sentences))\n",
    "print(len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sj9h4LlvanxE",
    "outputId": "7afbc56f-1bfa-4ac9-f256-78f1b5947f07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['would', 'have', 'a', 'hard', 'time', 'sitting', 'through', 'this', 'one']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jR_IJrltWK4E"
   },
   "outputs": [],
   "source": [
    "target=train.Sentiment.values\n",
    "y_target=to_categorical(target)\n",
    "num_classes=y_target.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "0xC64V4mazdT",
    "outputId": "89de29cf-27e6-4886-9e35-f7a9bca69eae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SQw-Sk-2YBFh"
   },
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(train_sentences,y_target,test_size=0.2,stratify=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "irNT_zDRYECQ",
    "outputId": "f01a80c2-3899-451a-ec26-c618bdec0f15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124848/124848 [00:00<00:00, 540493.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13735\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " #It is needed for initializing tokenizer of keras and subsequent padding\n",
    "\n",
    "unique_words = set()\n",
    "len_max = 0\n",
    "\n",
    "for sent in tqdm(X_train):\n",
    "    \n",
    "    unique_words.update(sent)\n",
    "    \n",
    "    if(len_max<len(sent)):\n",
    "        len_max = len(sent)\n",
    "        \n",
    "#length of the list of unique_words gives the no of unique words\n",
    "print(len(list(unique_words)))\n",
    "print(len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "B3Sdkfj1YSHf",
    "outputId": "5b754f60-4932-4227-b1b5-523078b992c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 4605.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'dose', 'is', 'strong', 'and', 'funny', 'for', 'the', 'first', 'minute', 'anyway', 'after', 'that', 'the', 'potency', 'wane', 'dramatically']\n",
      "['cletis', 'tout', 'might', 'inspire', 'a', 'trip', 'to', 'the', 'video', 'store', 'in', 'search', 'of', 'a', 'better', 'movie', 'experience']\n",
      "['time', 'to', 'let', 'your', 'hair', 'down']\n",
      "['lrb', 'crystal', 'and', 'de', 'niro', 'rrb']\n",
      "['silent', 'lumpish', 'cipher']\n",
      "['the', 'studio', 'did', 'n', 't', 'offer', 'an', 'advance', 'screening']\n",
      "['turn']\n",
      "['with', 'enjoyable', 'performance']\n",
      "['an', 'homage', 'to', 'them', 'tarantula', 'and', 'other', 'low']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm(X_train[1:10]):\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OtBHZfqFa6ky",
    "outputId": "ba18172a-0e4a-4691-fb18-e21e8994db39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124848, 48) (31212, 48) (66292, 48)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "#padding done to equalize the lengths of all input reviews. LSTM networks needs all inputs to be same length.\n",
    "#Therefore reviews lesser than max length will be made equal using extra zeros at end. This is padding.\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=len_max)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=len_max)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=len_max)\n",
    "print(X_train.shape,X_val.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "pZcIGbCQbeYp",
    "outputId": "607faf8d-ffa8-4355-9eb8-5fe401c15ecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 48, 300)           4120500   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 48, 128)           219648    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               6500      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 4,396,561\n",
      "Trainable params: 4,396,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(min_delta = 0.001, mode = 'max', monitor='val_acc', patience = 2)\n",
    "callback = [early_stopping]\n",
    "\n",
    "#Model using Keras LSTM\n",
    "model=Sequential()\n",
    "model.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
    "model.add(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
    "model.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.005),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3icAexllA0vD",
    "outputId": "51af20f0-f5d6-4b53-e0ef-650c368ec2af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './logs/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -R ./logs/ # rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "hVpUGE4TAM-G",
    "outputId": "84a142e7-7d6b-4fba-95f5-81e3b16c6f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/4\n",
      "124848/124848 [==============================] - 92s 736us/step - loss: 1.0107 - acc: 0.5955 - val_loss: 0.8501 - val_acc: 0.6531\n",
      "Epoch 2/4\n",
      "124848/124848 [==============================] - 89s 710us/step - loss: 0.8067 - acc: 0.6699 - val_loss: 0.8164 - val_acc: 0.6624\n",
      "Epoch 3/4\n",
      "124848/124848 [==============================] - 88s 708us/step - loss: 0.7388 - acc: 0.6937 - val_loss: 0.8183 - val_acc: 0.6694\n",
      "Epoch 4/4\n",
      "124848/124848 [==============================] - 88s 708us/step - loss: 0.6938 - acc: 0.7092 - val_loss: 0.8358 - val_acc: 0.6645\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=4, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "Azt5WFhKABL0",
    "outputId": "b4045caa-7956-4070-c750-f8d5ae8d5ab1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIJKVmIiEhCShYiIpKQkoWIiCT0/wFr0iyboXx13wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Visualize learning curve. Here learning curve is not ideal. It should be much smoother as it decreases.\n",
    "#As mentioned before, altering different hyper parameters especially learning rate can have a positive impact\n",
    "#on accuracy and learning curve.\n",
    "plt.plot(epoch_count, history.history['loss'], 'r--')\n",
    "plt.plot(epoch_count, history.history['val_loss'], 'b-')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9T2tHaeJAIIE"
   },
   "outputs": [],
   "source": [
    "# What is the final loss and accuracy on our validation data?\n",
    "valid_loss, valid_acc = model.evaluate_generator(valid_data_gen, steps=nb_valid_steps)\n",
    "print(f\"Final validation accuracy: {valid_acc*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dl task-5.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
