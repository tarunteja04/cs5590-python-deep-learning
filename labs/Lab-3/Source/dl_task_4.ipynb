{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl task-4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "2p6chuDCStiH",
        "colab_type": "code",
        "outputId": "a67c0321-3e64-40f9-8622-7b29567a9e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xBNrxPMXTpPE",
        "colab_type": "code",
        "outputId": "80a0b595-0d84-44ae-9f72-022cdf2c550f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from keras.utils import to_categorical\n",
        "import random\n",
        "from tensorflow import set_random_seed\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense,Dropout,Embedding,LSTM\n",
        "from keras.layers import Dense, Activation,Flatten\n",
        "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#set random seed for the session and also for tensorflow that runs in background for keras\n",
        "set_random_seed(123)\n",
        "random.seed(123)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "M_2veojIUMvJ",
        "colab_type": "code",
        "outputId": "84e273b6-6676-48c7-eb1d-b3475a5030b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "train= pd.read_csv(\"./drive/My Drive/sentiment review/train.tsv\", sep=\"\\t\")\n",
        "test = pd.read_csv(\"./drive/My Drive/sentiment review/test.tsv\", sep=\"\\t\")\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  SentenceId                                             Phrase  \\\n",
              "0         1           1  A series of escapades demonstrating the adage ...   \n",
              "1         2           1  A series of escapades demonstrating the adage ...   \n",
              "2         3           1                                           A series   \n",
              "3         4           1                                                  A   \n",
              "4         5           1                                             series   \n",
              "\n",
              "   Sentiment  \n",
              "0          1  \n",
              "1          2  \n",
              "2          2  \n",
              "3          2  \n",
              "4          2  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "tWAgDxHRUnif",
        "colab_type": "code",
        "outputId": "31f9099a-cc2c-4725-c880-b915a7b6d5ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train['Phrase'][100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'would have a hard time sitting through this one .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Iq8UE8L9Vid-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_sentences(df):\n",
        "    reviews = []\n",
        "\n",
        "    for sent in tqdm(df['Phrase']):\n",
        "        \n",
        "        #remove html content\n",
        "        review_text = BeautifulSoup(sent).get_text()\n",
        "        \n",
        "        #remove non-alphabetic characters\n",
        "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
        "    \n",
        "        #tokenize the sentences\n",
        "        words = word_tokenize(review_text.lower())\n",
        "    \n",
        "        #lemmatize each word to its lemma\n",
        "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
        "    \n",
        "        reviews.append(lemma_words)\n",
        "\n",
        "    return(reviews)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "olPqLpJRWtPc",
        "colab_type": "code",
        "outputId": "a0a2fa1a-100b-4d6c-c48c-5780221412a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4276
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "aFbY-Ug_WC2N",
        "colab_type": "code",
        "outputId": "2fbeb092-011b-492f-b001-f9adacbe543e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        " \n",
        "#cleaned reviews for both train and test set retrieved\n",
        "train_sentences = clean_sentences(train)\n",
        "test_sentences = clean_sentences(test)\n",
        "print(len(train_sentences))\n",
        "print(len(test_sentences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 156060/156060 [01:05<00:00, 2393.28it/s]\n",
            "100%|██████████| 66292/66292 [00:28<00:00, 2358.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "156060\n",
            "66292\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "sj9h4LlvanxE",
        "colab_type": "code",
        "outputId": "13844a38-288b-4f2d-afd4-5264ff8f3245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_sentences[100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['would', 'have', 'a', 'hard', 'time', 'sitting', 'through', 'this', 'one']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "jR_IJrltWK4E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target=train.Sentiment.values\n",
        "y_target=to_categorical(target)\n",
        "num_classes=y_target.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xC64V4mazdT",
        "colab_type": "code",
        "outputId": "ef461fcc-25ea-4a34-8a07-ff673a51b5cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "y_target"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "SQw-Sk-2YBFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train,X_val,y_train,y_val=train_test_split(train_sentences,y_target,test_size=0.2,stratify=y_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "irNT_zDRYECQ",
        "colab_type": "code",
        "outputId": "6536272c-41fd-43f5-87c6-d71a0c150eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        " #It is needed for initializing tokenizer of keras and subsequent padding\n",
        "\n",
        "unique_words = set()\n",
        "len_max = 0\n",
        "\n",
        "for sent in tqdm(X_train):\n",
        "    \n",
        "    unique_words.update(sent)\n",
        "    \n",
        "    if(len_max<len(sent)):\n",
        "        len_max = len(sent)\n",
        "        \n",
        "#length of the list of unique_words gives the no of unique words\n",
        "print(len(list(unique_words)))\n",
        "print(len_max)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 124848/124848 [00:00<00:00, 538459.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13734\n",
            "48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "B3Sdkfj1YSHf",
        "colab_type": "code",
        "outputId": "47f3cc72-b417-4463-808f-519bdd94b1fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "cell_type": "code",
      "source": [
        "for x in tqdm(X_train[1:10]):\n",
        "  print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 2134.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['thumb', 'down']\n",
            "['eloquently', 'about', 'the', 'symbiotic', 'relationship', 'between', 'art', 'and', 'life']\n",
            "['all', 'inclusive', 'world']\n",
            "['gosford', 'park', 'lrb', 'a', 'well', 'a', 'one', 'm', 'mirren', 'who', 'did', 'rrb']\n",
            "['roussillon', 'providing', 'comic', 'relief']\n",
            "['she', 'box', 'these', 'woman', 's', 'soul', 'right', 'open', 'for', 'u']\n",
            "['unique', 'and', 'quirky']\n",
            "['to', 'wonder', 'if']\n",
            "['called', 'any', 'kind', 'of', 'masterpiece']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OtBHZfqFa6ky",
        "colab_type": "code",
        "outputId": "74c43eaa-d431-49f9-bd95-f3915465ce68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "#padding done to equalize the lengths of all input reviews. LSTM networks needs all inputs to be same length.\n",
        "#Therefore reviews lesser than max length will be made equal using extra zeros at end. This is padding.\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=len_max)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=len_max)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=len_max)\n",
        "print(X_train.shape,X_val.shape,X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(124848, 48) (31212, 48) (66292, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pZcIGbCQbeYp",
        "colab_type": "code",
        "outputId": "1ad77436-f4d7-4f46-a167-c986a30c22d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "#Model using Keras CNN\n",
        "model=Sequential()\n",
        "model.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
        "model.add(Conv1D(128,5,activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Conv1D(128,5,activation='relu'))\n",
        "#model.add(MaxPooling1D(35))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.005),metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 48, 300)           4120200   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 44, 128)           192128    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 4, 128)            82048     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               51300     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 4,446,181\n",
            "Trainable params: 4,446,181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bIshDRjXQIDr",
        "colab_type": "code",
        "outputId": "2e126cdb-cec0-47b9-f131-7421081a0a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=4, batch_size=256, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 124848 samples, validate on 31212 samples\n",
            "Epoch 1/4\n",
            "124848/124848 [==============================] - 12s 98us/step - loss: 1.2168 - acc: 0.5307 - val_loss: 1.1341 - val_acc: 0.5630\n",
            "Epoch 2/4\n",
            "124848/124848 [==============================] - 6s 48us/step - loss: 1.1024 - acc: 0.5807 - val_loss: 1.1096 - val_acc: 0.5812\n",
            "Epoch 3/4\n",
            "124848/124848 [==============================] - 6s 47us/step - loss: 1.0575 - acc: 0.5986 - val_loss: 1.0935 - val_acc: 0.5797\n",
            "Epoch 4/4\n",
            "124848/124848 [==============================] - 6s 46us/step - loss: 1.0250 - acc: 0.6108 - val_loss: 1.1268 - val_acc: 0.5883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "42rD3t40SA-X",
        "colab_type": "code",
        "outputId": "5b450a4a-0823-4943-8f2d-38f2497fd314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(history.history['loss']) + 1)\n",
        "\n",
        "# Visualize learning curve. Here learning curve is not ideal. It should be much smoother as it decreases.\n",
        "#As mentioned before, altering different hyper parameters especially learning rate can have a positive impact\n",
        "#on accuracy and learning curve.\n",
        "plt.plot(epoch_count, history.history['loss'], 'r--')\n",
        "plt.plot(epoch_count, history.history['val_loss'], 'b-')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "QQSpDAcxSQu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# What is the final loss and accuracy on our validation data?\n",
        "valid_loss, valid_acc = model.evaluate_generator(valid_data_gen, steps=nb_valid_steps)\n",
        "print(f\"Final validation accuracy: {valid_acc*100:.2f}%\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}